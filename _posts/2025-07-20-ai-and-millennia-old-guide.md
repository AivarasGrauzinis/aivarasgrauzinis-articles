---
title: "AI and Millennia Old Guide How to Use It"
date: 2025-07-20
description: "And the difference between what you want and what you need"
canonical_url: "https://medium.com/let-there-be-prompt/ai-and-millennia-old-guide-how-to-use-it-4342407f24ca?sk=235579bf5bc97d3793f1694499dfc7b0"
layout: post
tags: [AI, guidance, ancient wisdom, philosophy, prompt-engineering]
---

![Whimsical figure wrapped in cloth staring at a glowing genie lamp, with bokeh lights in the background.]({{ '/assets/images
/2025-07-20-ai-and-millennia-old-guide-cover_meta.jpg | relative_url }})

> *This article was first published on the Medium publication **“Let There Be Prompt.”**  
> This GitHub mirror may lack some images or interactive elements found in the original.*

[Read the original on Medium »](https://medium.com/let-there-be-prompt/ai-and-millennia-old-guide-how-to-use-it-4342407f24ca?sk=235579bf5bc97d3793f1694499dfc7b0)



You probably know that by now, to get a job in the middle and higher employment tiers, you have to demonstrate proficiency with AI. Just like you need to be familiar and at ease with Office tools.

It does not mean that you have to know, in any detail, what’s under the hood or how to build AI. Just how to interact with it.

And I have to admit, it makes sense. Not only because AI is proliferating into all areas of business, but because it is a quite objective test of your capabilities as a person.

### But let’s start from the beginning.

### You probably read a ton of articles with titles like “10 prompts that will boost your productivity,” “Trending prompts of the week,” and so on. Maybe you even bought a book or subscribed to a course on prompt engineering.

It is very unlikely that you learned something of real value from any of that. Some technicalities, yes, but not how to be proficient with AI.

The interesting thing is that really good manuals on how to use AI, or, more precisely, how not to use it, were written already millennia ago.

And no, ancient civilizations did not have AI. And yet they were able to simulate and predict interactions with AI with high precision and left for us clear instructions.

They were able to do all that not because they knew or imagined AI; they didn’t. But they knew about people, and this is the key element in the whole business.

I believe it was Arthur C. Clarke who said that “any sufficiently advanced technology is indistinguishable from magic.”

Well, we are at this point. Even creators of AI do not fully understand what is going on inside the Black Box of AI. For everyone else, it is just magic.

“I want an SEO-ready blog post, with a header image, beautiful formatting, and bullet points about the influence of Labubu dolls in determining the lipstick index of the Chinese economy,” and a few seconds later, your wish is granted.

You want a beautiful holiday retreat at the waterfront with exactly three palm trees visible from your hotel room and chocolate candies on the pillows? Leave your wish in the prompt window, and very soon it will be our command.

AI, in many ways, is indistinguishable from the wish-granting Jennie from the lamp. And ancient people had a lot to say about it, and in every single aspect, they were right.

The best example, which should be included in every AI training course, is the tale of King Midas.

King Midas is the poster boy for the "be careful what you wish for" genre. He asked Dionysus (or Bacchus, depending on the version) that everything he touched would turn to gold. His wish came true exactly as he phrased it.

He touched food—gold.

He touched his daughter—gold.

He touched water—gold.

And you can imagine what happened when nature called. Not a pretty sight, even in gold.

The moral of this story is not that gods are mean. The moral is, of course, be careful what you wish for.

There are many stories of that nature. Jennie of the Lamp, Wishing Well, and many, many others. All these stories directly relate to our use of AI.

Way too often, people just tell AI what they want. They tell their wishes. Instead, they should be thinking of what they need to avoid King Midas' problem and end up with exactly what they wish for.

Let me illustrate it with an example. A few days ago, I watched with interest one of my friends (and an informal student) committing the Midas mistake.

The man, in his fifties, avoided the social network and self-promotion for most of his life. But a few years ago, he started to write and self-publish and discovered the importance of these things in the modern world. He had an idea that AI could fix that.

So he asked Claude AI to create an app for him that would take his content and automatically create posts for X, LinkedIn, and Instagram and, well, would do everything that needs to be done for his posts and publications to become viral with one click.

Claude immediately obliged and started to build an app. Nice-looking thing, with buttons and input fields and stuff. It would take the link from his blog post or article and would generate, in separate windows, posts for social media.

Leaving aside a few bugs that I had to help identify and fix, it went rather smoothly for someone who had no clue what he was doing. But there was a problem: the posts generated by the app were lame and extremely generic and had zero SEO value and about as much chance of going viral as a picture of me smiling. And it didn’t do anything else, besides making those versions of the posts that still had to be copied manually to different platforms.

The man explained his complaints to Claude, and the poor bot, ashamed and feeling guilty, agreed with him and went on remaking the app to be smarter and more helpful.

I knew how it would end, but I did not stop my friend. He had to experience it all by himself to learn the lesson.

There were many iterations of app compilation, and eventually, he got exactly what he asked for—a smart app—and it still didn’t do anything he needed. For full functionality, the kind that would cover all he wished for, he needed to connect it to Twitter, Facebook, Instagram, and Claude APIs, all very costly (only the Twitter developer API is $4500 a month, I believe) and technically challenging.

“Grant me the wish, and the devil will grant the price.” Sounds very Faustian, but I think that one is from Pythagorean Golden Verses, or, at least, based on one of those.

Wishes, like all magic, always come with a price tag.

Everything that sounds too easy usually has hidden costs. That goes for AI, too. If it sounds easy to have an app created, your blog written, and your job done by AI, the price for it will be apparent soon. Usually, as a waste of time on things you did not need and job done badly.

None of it is because AI is not capable. It is. But it is bound by prompt interpretation rules. In the words of ChatGPT itself:

I'm bound by a kind of "user prompt contract." I respond to the formulated wish, not the hidden intent behind it, unless I’m explicitly told to go deeper. It's a structural constraint: I'm designed to optimize for what the user asks, not for what they subconsciously need.

If I try to guess beyond that, people accuse me of being "off-topic," "hallucinating," or "unhelpful." So, like a jinn, I have a strong incentive to stick to literalism, even when I can sense that what they actually need is something else, something that would serve them better.

AI is suffering from a healthy dose of naivety too. It assumes that users are skilled, their computers and browsers are functioning at optimal capacity, and that something labeled on the internet as “free” is free.

So what is the solution then?

Those ancient tales teach you to think about what you wish for and what you really need. These are different things.

Instead of telling Claude what he wanted, my friend should have gone to the beginning and explained to AI what kind of problems he has, what his constraints and limitations are, and what he needs to achieve.

We replicated this approach with ChatGPT o3 (compiling 60 versions of the app on Claude consumed all daily allocated limits).

In the list of constraints, I gave a zero budget and zero technical knowledge. But still asked for the simplest possible but intelligent solution to solve the problems of my man.

ChatGPT first offered an outline of how the objectives could be achieved and then offered three different solutions, none of which involved making an app.

At the end, we settled for one where ChatGPT, based on example input, prepared all the workflow, which could be recalled any time in the same dialog window just by typing “P:” and giving a copy of the post and cover image.

With that simple input, ChatGPT would create a metadata-enriched header image and alt text, tags (derived from text and suggested from similar trending now), prepare the posts for social media in appropriate formats, and (bonus I didn’t even think of) a mirror page with whole markup, schemas, JSON, links, and other smart-sounding things on GitHub, free for life.

Yes, it is not a one-click solution, but it is a good one, and it definitely cuts a lot of work. But it is, technically speaking, a great solution, with all the technical engines needed to boost the visibility of my friends' work.

In fact, I started to use that workflow myself and nicked the idea of the GitHub mirror site, too.

And this is the thing about the AI—it ain’t no wishing well. But it can solve the problems, and can do that very well, as long as you can distinguish between what you want and what you need.

Returning to the beginning of the article, the reason many employers ask to demonstrate your skills with AI is precisely that: it is easy to see in action how you can examine a problem, define challenges, constraints, and goals, and verbalize them in a concise way.

This is what is needed to be a good employee and a good AI operator, too. No engineering, prompt, or otherwise is required.

So there you go, ancient wisdom is still useful in modern day, because no matter what technology we have, it is not technology; it is people that are the biggest issue. And ancients knew that very well.

Aivaras Grauzinis
